{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = Roboflow(api_key=\"RRJitllisZT37MLdkgjz\")\n",
    "# project = rf.workspace(\"project-rt7v1\").project(\"-b107j\")\n",
    "# version = project.version(4)\n",
    "# dataset = version.download(\"coco\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Keypoint config check:\n",
      "NUM_KEYPOINTS: 4\n",
      "OKS_SIGMAS length: 4\n",
      "OKS_SIGMAS value: [0.5, 0.5, 0.5, 0.5]\n",
      "\u001b[32m[04/05 00:59:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (keypoint_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=2, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=2, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=2, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=2, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (keypoint_head): KRCNNConvDeconvUpsampleHead(\n",
      "      (conv_fcn1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu1): ReLU()\n",
      "      (conv_fcn2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu2): ReLU()\n",
      "      (conv_fcn3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu3): ReLU()\n",
      "      (conv_fcn4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu4): ReLU()\n",
      "      (conv_fcn5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu5): ReLU()\n",
      "      (conv_fcn6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu6): ReLU()\n",
      "      (conv_fcn7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu7): ReLU()\n",
      "      (conv_fcn8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn_relu8): ReLU()\n",
      "      (score_lowres): ConvTranspose2d(512, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/05 00:59:08 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 53 images left.\n",
      "\u001b[32m[04/05 00:59:08 d2.data.build]: \u001b[0mRemoved 0 images with fewer than 1 keypoints.\n",
      "\u001b[32m[04/05 00:59:08 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   skater   | 53           |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[04/05 00:59:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/05 00:59:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/05 00:59:08 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/05 00:59:08 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 00:59:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[32m[04/05 00:59:08 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[04/05 00:59:08 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x/137849621/model_final_a6e10b.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.keypoint_head.score_lowres.weight' to the model due to incompatible shapes: (512, 17, 4, 4) in the checkpoint but (512, 4, 4, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.keypoint_head.score_lowres.bias' to the model due to incompatible shapes: (17,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.keypoint_head.score_lowres.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/05 00:59:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Documents/PAC2/detectron2/detectron2/structures/keypoints.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  keypoints = torch.as_tensor(keypoints, dtype=torch.float32, device=device)\n",
      "/home/ilya/Documents/PAC2/detectron2/detectron2/structures/keypoints.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  keypoints = torch.as_tensor(keypoints, dtype=torch.float32, device=device)\n",
      "/home/ilya/Documents/PAC2/detectron2/detectron2/structures/keypoints.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  keypoints = torch.as_tensor(keypoints, dtype=torch.float32, device=device)\n",
      "/home/ilya/Documents/PAC2/detectron2/detectron2/structures/keypoints.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  keypoints = torch.as_tensor(keypoints, dtype=torch.float32, device=device)\n",
      "/home/ilya/miniconda3/envs/keypoint/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/05 00:59:16 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   skater   | 2            |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[04/05 00:59:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/05 00:59:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/05 00:59:16 d2.data.common]: \u001b[0mSerializing 2 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 00:59:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[04/05 00:59:16 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'my_dataset_val' to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/05 00:59:16 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at './output/evaluation/my_dataset_val_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[04/05 00:59:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 2 batches\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.535647 (1.535647 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (1.493510 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/evaluation/coco_instances_results.json\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.050\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for keypoints: \n",
      "|  AP   |  AP50  |  AP75  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|\n",
      "| 2.525 | 25.248 | 0.000  |  nan  | 2.525 |\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[04/05 00:59:19 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: keypoints\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APm,APl\n",
      "\u001b[32m[04/05 00:59:19 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5248,25.2475,0.0000,nan,2.5248\n",
      "\u001b[32m[04/05 00:59:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/05 00:59:26 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/05 00:59:26 d2.data.common]: \u001b[0mSerializing 2 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 00:59:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[04/05 00:59:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 2 batches\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.533829 (1.533829 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (1.473627 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/evaluation/coco_instances_results.json\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.050\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for keypoints: \n",
      "|  AP   |  AP50  |  AP75  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|\n",
      "| 2.525 | 25.248 | 0.000  |  nan  | 2.525 |\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[04/05 00:59:29 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: keypoints\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APm,APl\n",
      "\u001b[32m[04/05 00:59:29 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5248,25.2475,0.0000,nan,2.5248\n",
      "\u001b[32m[04/05 00:59:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/05 00:59:36 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/05 00:59:36 d2.data.common]: \u001b[0mSerializing 2 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 00:59:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[04/05 00:59:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 2 batches\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.508643 (1.508643 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (1.456840 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/evaluation/coco_instances_results.json\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.050\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for keypoints: \n",
      "|  AP   |  AP50  |  AP75  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|\n",
      "| 2.525 | 25.248 | 0.000  |  nan  | 2.525 |\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[04/05 00:59:39 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: keypoints\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APm,APl\n",
      "\u001b[32m[04/05 00:59:39 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5248,25.2475,0.0000,nan,2.5248\n",
      "\u001b[32m[04/05 00:59:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/05 00:59:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/05 00:59:48 d2.data.common]: \u001b[0mSerializing 2 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 00:59:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[04/05 00:59:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 2 batches\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.635362 (1.635362 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (1.567328 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/evaluation/coco_instances_results.json\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.050\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for keypoints: \n",
      "|  AP   |  AP50  |  AP75  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|\n",
      "| 2.525 | 25.248 | 0.000  |  nan  | 2.525 |\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[04/05 00:59:52 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: keypoints\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APm,APl\n",
      "\u001b[32m[04/05 00:59:52 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5248,25.2475,0.0000,nan,2.5248\n",
      "\u001b[32m[04/05 00:59:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/05 00:59:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/05 00:59:59 d2.data.common]: \u001b[0mSerializing 2 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/05 00:59:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[04/05 00:59:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 2 batches\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.611035 (1.611035 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (1.548018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/evaluation/coco_instances_results.json\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.050\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for keypoints: \n",
      "|  AP   |  AP50  |  AP75  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|\n",
      "| 2.525 | 25.248 | 0.000  |  nan  | 2.525 |\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[04/05 01:00:02 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: keypoints\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APm,APl\n",
      "\u001b[32m[04/05 01:00:02 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5248,25.2475,0.0000,nan,2.5248\n",
      "\u001b[32m[04/05 01:00:14 d2.engine.hooks]: \u001b[0mOverall training speed: 3 iterations in 0:00:35 (11.7335 s / it)\n",
      "\u001b[32m[04/05 01:00:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:47 (0:00:12 on hooks)\n",
      "\u001b[32m[04/05 01:00:14 d2.utils.events]: \u001b[0m eta: 4:07:14  iter: 5  total_loss: 8.458  loss_cls: 0.148  loss_box_reg: 0.1057  loss_keypoint: 8.133  loss_rpn_cls: 0.05978  loss_rpn_loc: 0.02202    time: 7.8776  last_time: 7.4395  data_time: 0.0243  last_data_time: 0.0009   lr: 1.396e-06  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 148\u001b[0m\n\u001b[1;32m    146\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(cfg)\n\u001b[1;32m    147\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 148\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PAC2/detectron2/detectron2/engine/defaults.py:520\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m    Run training.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mTEST\u001b[38;5;241m.\u001b[39mEXPECTED_RESULTS) \u001b[38;5;129;01mand\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    523\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_last_eval_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo evaluation results obtained during training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/PAC2/detectron2/detectron2/engine/train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/PAC2/detectron2/detectron2/engine/defaults.py:530\u001b[0m, in \u001b[0;36mDefaultTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PAC2/detectron2/detectron2/engine/train_loop.py:322\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    If you need to accumulate gradients or do something similar, you can\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    wrap the optimizer with your custom `zero_grad()` method.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 322\u001b[0m \u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_backward()\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_write_metrics:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# write metrics asynchronically\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/keypoint/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/keypoint/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/keypoint/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1.     \n",
    "# ----------------------------------------------\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        return COCOEvaluator(\n",
    "            dataset_name=dataset_name,\n",
    "            output_dir=os.path.join(cfg.OUTPUT_DIR, \"evaluation\"),\n",
    "            use_fast_impl=False,\n",
    "        )\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2.    (   )\n",
    "# ----------------------------------------------\n",
    "def load_keypoints_dataset(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    #   \n",
    "    assert \"categories\" in data, \"Categories section is missing in annotations!\"\n",
    "    assert len(data[\"categories\"]) > 0, \"No categories defined!\"\n",
    "    \n",
    "    image_dict = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for ann in data[\"annotations\"]:\n",
    "        #           \n",
    "        record = {}\n",
    "        image_id = ann[\"image_id\"]\n",
    "        image_info = image_dict[image_id]\n",
    "        \n",
    "        #    \n",
    "        image_dir = os.path.join(os.path.dirname(json_file))  #   images\n",
    "        record[\"file_name\"] = os.path.join(image_dir, image_info[\"file_name\"])\n",
    "        \n",
    "        #   \n",
    "        if not os.path.exists(record[\"file_name\"]):\n",
    "            raise FileNotFoundError(f\"Image not found: {record['file_name']}\")\n",
    "\n",
    "        record[\"width\"] = image_info[\"width\"]\n",
    "        record[\"height\"] = image_info[\"height\"]\n",
    "        record[\"image_id\"] = image_id\n",
    "\n",
    "        record[\"annotations\"] = [{\n",
    "            \"bbox\": ann[\"bbox\"],\n",
    "            \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "            \"keypoints\": ann[\"keypoints\"],\n",
    "            \"num_keypoints\": 4,\n",
    "            \"category_id\": 0,\n",
    "            \"iscrowd\": ann.get(\"iscrowd\", 0)\n",
    "        }]\n",
    "        \n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "    return dataset_dicts\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 3.   ( FLIP_MAP)\n",
    "# ----------------------------------------------\n",
    "TRAIN_JSON = \"/home/ilya/Documents/PAC2/--4/train/_annotations.coco.json\"\n",
    "VAL_JSON = \"/home/ilya/Documents/PAC2/--4/valid/_annotations.coco.json\"\n",
    "\n",
    "#   \n",
    "for name in [\"my_dataset_train\", \"my_dataset_val\"]:\n",
    "    if name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(name)\n",
    "    if name in MetadataCatalog.list():\n",
    "        MetadataCatalog.remove(name)\n",
    "\n",
    "DatasetCatalog.register(\"my_dataset_train\", lambda: load_keypoints_dataset(TRAIN_JSON))\n",
    "DatasetCatalog.register(\"my_dataset_val\", lambda: load_keypoints_dataset(VAL_JSON))\n",
    "\n",
    "#    flip_map\n",
    "KEYPOINT_METADATA = {\n",
    "    \"thing_classes\": [\"skater\"],\n",
    "    \"keypoint_names\": [\"head\", \"left_shoulder\", \"right_shoulder\", \"pelvis\"],\n",
    "    \"keypoint_flip_map\": [(1, 2), (0, 3)],  #   \n",
    "    \"keypoint_skeleton\": [[0, 1], [1, 3], [2, 3]],\n",
    "    \"keypoint_sigmas\": [0.5, 0.5, 0.5, 0.5],\n",
    "    \"evaluator_type\": \"coco\"\n",
    "}\n",
    "\n",
    "for name in [\"my_dataset_train\", \"my_dataset_val\"]:\n",
    "    MetadataCatalog.get(name).set(**KEYPOINT_METADATA)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4.   ( )\n",
    "# ----------------------------------------------\n",
    "cfg = get_cfg()\n",
    "\n",
    "#  \n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 2  #   \n",
    "#  :\n",
    "# 1.      \n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = [0.5] * 4\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NAME = \"KRCNNConvDeconvUpsampleHead\"\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 4\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.POOLER_RESOLUTION = 14\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.POOLER_SAMPLING_RATIO = 2\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.CONV_DIMS = [512] * 8\n",
    "\n",
    "# 2.   OKS \n",
    "\n",
    "# 3.     \n",
    "\n",
    "#  \n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  #   \n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 500\n",
    "cfg.SOLVER.STEPS = (100, 150)\n",
    "cfg.TEST.EVAL_PERIOD = 50\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 5.    \n",
    "# ----------------------------------------------\n",
    "\n",
    "print(\"\\nFinal Keypoint config check:\")\n",
    "print(f\"NUM_KEYPOINTS: {cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS}\")\n",
    "print(f\"OKS_SIGMAS length: {len(cfg.TEST.KEYPOINT_OKS_SIGMAS)}\")\n",
    "print(f\"OKS_SIGMAS value: {cfg.TEST.KEYPOINT_OKS_SIGMAS}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #  \n",
    "    metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "    #  \n",
    "    trainer = CustomTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
